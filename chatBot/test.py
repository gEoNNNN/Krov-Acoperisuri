import pandas as pd
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.schema import Document
from dotenv import load_dotenv
from chromadb.config import Settings as ClientSettings
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
import os
import re
import openai


load_dotenv()

llm = ChatOpenAI(temperature=0.2, model="gpt-4o")

df = pd.read_excel("chatBot/p.xlsx")
df.columns = df.columns.str.strip()
df["Categorie"] = df["Categorie"].ffill()
df = df[df["Nume"].notna() & df["Nume"].str.strip().ne("")]

categorii = df["Categorie"].dropna().unique().tolist()
categorii = [c.strip().replace(":", "").replace("Categorie", "") for c in categorii]
categorii = list(set(categorii))

print("ğŸ“‹ Categoriile disponibile sunt:")
for idx, cat in enumerate(categorii, 1):
    print(f"{idx}. {cat}")


culori_hex = {
    "roÈ™u oxizi": "#6E1414",
    "maro ciocolatiu": "#381819",
    "gri Ã®nchis": "#2F2F2F",
    "roÈ™u vin": "#800020",
    "verde pÄƒdure": "#228B22",
    "gri grafit": "#474A51",
    "gri antracit": "#383E42",
    "negru intens": "#000000",
    "roÈ™u": "#FF0000",
    "albastru cobalt": "#0047AB",
    "alb semilucios": "#F5F5F5"
}



docs = []

categorii_text = "Lista categoriilor disponibile este:\n" + "\n".join([f"- {cat}" for cat in categorii])
docs.append(Document(page_content=categorii_text, metadata={"categorie": "lista_categorii"}))

for categorie, group in df.groupby("Categorie"):
    chunk_text = "\n\n".join([
        f"Nume: {row['Nume']}\nCategorie: {row['Categorie']}\nCulori: {row['Culori']}\nU/M: {row['u/m']}\nPreÈ› client: {row['PreÈ›ul Client']}\nPreÈ› listÄƒ: {row['PreÈ›ul de listÄƒ']}"
        for _, row in group.iterrows()
    ])
    docs.append(Document(page_content=chunk_text, metadata={"categorie": categorie}))



embedding_model = OpenAIEmbeddings()

vectorstore = Chroma.from_documents(
    docs,
    embedding_model,
    persist_directory="./vector_index",
    client_settings=ClientSettings(
        anonymized_telemetry=False,
        persist_directory="./vector_index"
    )
)


memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer')


qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever(search_kwargs={"k": 4}),
    chain_type="stuff",
    return_source_documents=True,

)


# while True:
#     question = input("\nâ“ Ãntrebare: ")
#     if question.lower() in ["exit", "quit"]:
#         break

#     result = qa_chain.invoke({"query": question})
#     print("\nğŸ“Š RÄƒspuns:\n", result['result'])


#     source_doc = result.get('source_documents', [None])[0]
#     if source_doc:
#         print(f"ğŸ“‚ Categorie folositÄƒ pentru rÄƒspuns: {source_doc.metadata.get('categorie')}")

def extrage_culori_si_coduri(result1_result, culori_hex):
    # Extrage partea cu lista culorilor
    lista_culori = re.findall(r"(?i)(roÈ™u oxizi|maro ciocolatiu|gri Ã®nchis|roÈ™u vin|verde pÄƒdure|gri grafit|gri antracit|negru intens|roÈ™u|albastru cobalt|alb semilucios)", result1_result, re.IGNORECASE)

    # NormalizeazÄƒ È™i eliminÄƒ duplicatele
    culori_gasite = sorted(set([c.lower().strip() for c in lista_culori]))

    # GenereazÄƒ listÄƒ HTML cu numele È™i codul
    culori_formatate = []
    for culoare in culori_gasite:
        hex_code = culori_hex.get(culoare)
        print(hex_code)
        if hex_code:
            # exemplu de bulinÄƒ coloratÄƒ + nume
            culori_formatate.append(
                f"<div style='margin-bottom:10px; display: flex; align-items: center;'>"
                f"<span style='display:inline-block;width:35px;height:35px;background:{hex_code};"
                f"border-radius:50%;margin-right:10px;'></span>"
                f"{culoare.title()}</div>"
            )

        else:
            culori_formatate.append(culoare.title())

    return "<br><br><b>Culori disponibile:</b><br>" + " ".join(culori_formatate)


def ask_with_ai(messages , temperature = 0.9 , max_tokens = 100):
    response = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens
    )
    return response.choices[0].message.content.strip()


def ask_with_ai_3(messages , temperature = 0.3 , max_tokens = 100):
    response = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens
    )
    return response.choices[0].message.content.strip()

def categoria_preferata(categoria,alegere_preturi):
    print(categoria)
    if alegere_preturi == "lista":
        question = f"Vreau sa vad toate produsele din categoria {categoria} cu pretul din lista"
    elif alegere_preturi == "client":
        question = f"Vreau sa vad toate produsele din categoria {categoria} cu pretul pentru client"
    
    question1 = f"Vreau sa vad toate culorile din categoria {categoria}"
    
    result = qa_chain.invoke({"query": question})
    result1 = qa_chain.invoke({"query": question1})
    

    if "RoÈ™u" in result1['result'] or "Gri Ã®nchis" in result1['result'] or "Maro ciocolatiu" in result1['result'] or "RoÈ™u vin" in result1['result'] or "Gri antracit" in result1['result'] or "Albastru cobalt" in result1['result'] or "Alb semilucios" in result1['result']:
        decizie = "DA"
    else:
        decizie = "NU" 

    if decizie == "DA":
        culori_formatate = extrage_culori_si_coduri(result1['result'], culori_hex)
    else:
        culori_formatate = "Culorile nu sunt specificate (poti alege orice culoare la urmatorul pas). <br><br>"

    result_final = result['result'] + "\n\n<br><br>" + culori_formatate
    return result_final

# question = f"Vreau sa vad toate produsele din categoria china mat cu pretul din lista"


# result = qa_chain.invoke({"query": question})

# prompt = (
#     f"Te rog sÄƒ traduci Ã®ntreg conÈ›inutul urmÄƒtor Ã®n limba rusÄƒ, pÄƒstrÃ¢nd fix aceeaÈ™i structurÄƒ, formatare È™i format ca Ã®n textul original:\n\n"
#     f"{result['result']}\n\n"
#     "Nu schimba nimic Ã®n afarÄƒ de limbÄƒ, pÄƒstreazÄƒ toate elementele, formatÄƒrile, semnele de punctuaÈ›ie È™i ordinea exactÄƒ."
# )

# messages = [{"role": "user", "content": prompt}]
# translated_text = ask_with_ai_3(messages, temperature=0.7, max_tokens=500)

# print(translated_text)

def traducere_produse(text):
    prompt = (
        f"Te rog sÄƒ traduci Ã®ntreg conÈ›inutul urmÄƒtor Ã®n limba rusÄƒ, pÄƒstrÃ¢nd fix aceeaÈ™i structurÄƒ, formatare È™i format ca Ã®n textul original:\n\n"
        f"{text}\n\n"
        "Nu schimba nimic Ã®n afarÄƒ de limbÄƒ, pÄƒstreazÄƒ toate elementele, formatÄƒrile, semnele de punctuaÈ›ie È™i ordinea exactÄƒ.\n"
        "Ãn special, traduce corect È™i profesional toate tipurile de acoperiÈ™uri, aÈ™a cum se folosesc Ã®n limbajul tehnic specific domeniului."
    )

    messages = [{"role": "user", "content": prompt}]
    translated_text = ask_with_ai_3(messages, temperature=0, max_tokens=700)

    return translated_text

